*18*
Деньжаков А.Ю., Шибанов С.В., Хмелевской Б.Г.
ЗАДАЧИ И МЕТОДЫ КОЛЛАБОРАТИВНОЙ ФИЛЬТРАЦИИ
Рассматривается понятие и происхождение коллаборативной фильтрации. Определяются типичные задачи, стоящие перед алгоритмами коллаборативной фильтрации, предметная область и перспективы развития. Приводится классификация методов коллаборативной фильтрации. Описываются примеры алгоритмов, использующихся в действующих системах. Производится сравнение алгоритмов коллаборативной
фильтрации для нахождения оптимального алгоритма для конкретной задачи.
В последнее десятилетие наблюдается взрывной рост объемов доступной обществу информации. Объем
всего этого значительно выше того, что может реально пропустить через себя человек, чтобы обнаружить то, что ему понравится.
Люди пытаются справляться с этими информационными перегрузками собственными силами, силами
других людей, но всё равно это не особо решает проблему. Большая часть вещей и информации теряется из виду людей просто потому, что они находятся вне их досягаемости или видимости. Во-вторых,
уже без нашего участия большой объём информации отфильтровывается. Так, например, редакторы газет
и журналов выбирают те статьи, которые их читатели хотят читать, книжные магазины решают, какие
книги выпустить в продажу, а рекламный бюджет определяет лидера в любой отрасли.
Таким образом, для решения упомянутых выше проблем нужны дополнительные технологии отфильтровывания. Главным методом персонифицированного информационного фильтрования является коллаборативная фильтрация. По существу оно автоматизирует процесс рекомендации в виде людской молвы, «изустной рекламы»: объекты рекомендуются пользователю на основании опыта взаимодействия с объектом
других людей.
В конечном счете, коллаборативная фильтрация (КФ) — метод, дающий автоматические прогнозы
(фильтрацию) относительно интересов пользователя по собранной информации о вкусах множества пользователей (сотрудничающих между собой).
Его основное допущение состоит в следующем: те, кто соглашался в прошлом, склонны согласиться
и в будущем. Например, система КФ или рекомендательная система по музыкальным вкусам способна
прогнозировать, какая музыка понравится пользователю, имея неполный список его предпочтений (симпатий и антипатий). Отметим, что эти прогнозы индивидуальны, хотя используемая информация собрана
от многих участников. Тем самым они отличаются от более простого подхода, дающего усреднённую
оценку для каждого объекта интереса, к примеру, базирующуюся на количестве поданных за него голосов.
Для определения задач, стоящих перед методами КФ, зададим общие определения и исходные данные.
Пусть U – множество субъектов (клиентов, пользователей: users) в некой взаимосвязанной системе
– клиентской среде. Примерами таких сред могут быть социальные сети, интернет-магазины, поисковые
машины, торговые сети, операторы сотовой связи и др.
Положим R – множество объектов клиентской среды (ресурсов, товаров, предметов: items).
Y – множество транзакции в клиентской среде. Примерами транзакци являются: использование сервиса или покупка товара, оценивание (рейтингование) сервиса или товара, обращение за информацией,
оплата услуг, выбор тарифного плана, участие в маркетинговой акции, получение бонуса от компании,
отказ от обслуживания, и т. д.
Тогда клиентская среда — это совокупность клиентов U, регулярно пользующихся фиксированным
набором сервисов R, и действия (транзакции) Y клиентов протоколируются в электронном виде.
Опишем протокол транзакций в клиентской среде:
На основе приведенных исходных данных и протокола транзакций можно построить матрицу всех возможных транзакций в клиентской среде, где F матрица размера.
Задачами анализа клиентских сред (АКС) являются эффективное вычисление взаимно согласованных
оценок сходства клиентов и сервисов, и использование их для решения таких бизнес-задач, как автоматизация маркетинговых исследований, формирование направленных предложений клиентам, персонализация сервисов, повышение удовлетворённости и лояльности клиентов, более эффективное привлечение
и удержание клиентов, основываясь при этом на обработке протоколов действий клиентов.
Работы по коллаборативной фильтрации в большинстве случаев ограничиваются узкими постановками
задач — предсказания рейтингов или формирования рекомендаций.
В общем виде задачами коллаборативной фильтрации являются:
предсказание незаполненных ячеек, например, рекомендации к покупке при заданной клиентской базе и номенклатуре;
оценивание сходства между субъектами, объектами и субъектами и объектами;
выявление скрытых интересов относительно заданного, либо неизвестного набора тем. Например,
рекомендация к потреблению какого-либо мультимедийного контента.
Рассмотрим примеры прикладных задач, решаемых с помощью методов КФ.
Рекомендующая система на основе бинарных данных (задача персонализации). В контексте задачи
будем считать: U – пользователи сети Интернет; R – ресурсы сети (сайты, документы, новости и
т.п.),
– пользователь u посетил ресурс r.
Используя основную гипотезу Web Usage Mining – действия (посещения) пользователя характеризуют
его интересы, вкусы, привычки, возможности – определим задачи персонализации:
выдать оценку ресурса r для пользователя u;
выдать пользователю u ранжированный список рекомендуемых ресурсов;
сгенерировать для ресурса r список близких ресурсов.
Задачи персонализации предложений. Пусть U – клиенты интернет-магазина; R – товары (книги, видео, музыка и т.п.),
– [клиент u купил товар r] или [рейтинг, который клиент u выставил товару r] . Тогда задачи персонализации предложений включают:
выдать оценку товара r для клиента u;
выдать клиенту u список рекомендуемых товаров;

 
предложить скидку на совместную покупку (cross-selling);
информировать клиента о новом товаре (up-selling);
сегментировать клиентскую базу;
выделить целевые аудитории по интересам.
Примером рекомендательной системы на основе рейтингов – конкурс Netflix [ё].
Анализ текстов. Пусть U – текстовые документы (статьи, новости и т.п.); R – ключевые слова и
выражения,
– частота встречаемости слова r в тексте u. Задачи анализа текстов тогда будут
включать:
кластеризацию текстов: сгруппировать тексты по тематике;
определить тематику нового текста (например, новости);
найти тексты той же тематики, что данный текст;
ранжировать найденные тексты по сходству;
построить иерархический каталог текстов;
описать каждый раздел набором ключевых слов.
Социальные сети, форумы, блоги. Будем считать: U – пользователи; R – текстовые документы (форумы, блоги); K – ключи (ключевые слова или выражения);

– пользователь u участвует в r;
– частота встречаемости ключа k в тексте r;
– пользователю u интересен пользователь v. Типичными задачами будут:
рекомендовать пользователю интересные ему блоги, найти единомышленников (like-minded people);
охарактеризовать интересы пользователя ключами;
найти все блоги по данным или похожим ключам;
найти все блоги, похожие на данный;
построить иерархический тематический каталог блогов.
Выделяют два основных класса коллаборативной фильтрации
Класс моделей, основанных на хранении исходных данных (Memory-Based Collaborative Filtering);
Класс неявных (латентных) моделей (Latent Models for Collaborative Filtering).
Методы первого класса наиболее распространены в настоящее время. Общий подход заключается в
хранении всей исходной матрицы данных F. В зависимости от того, объект или субъект является базисом для вычисления прогноза, выделяют два типа фильтрации в явных методах: по схожести объектов и
схожести субъектов.
Фильтрация по схожести объектов (item-based filtration) сравнивает оценки, данные различными
пользователями, где сходство объектов – корреляция столбцов матрицы F.
Если доступны оценки предмета, к примеру, пользователям дана возможность проголосовать за
предмет (например, выставить оценку от 1 до 5), то коллаборативная фильтрация пытается предсказать оценку, которую даст пользователь новому предмету на основании его предыдущих оценок и базы
данных оценок других пользователей.
Но далеко не всегда у пользователей есть возможность выставлять оценки предметам. То есть для
коллаборативной фильтрации могут быть доступны всего лишь двоичные данные (покупал пользователь
предмет или нет).
Примером алгоритма коллаборативной фильтрации по объектам, работающего с двоичными данными,
является запатентованный алгоритм Item-to-Item использующийся в онлайн-магазине Amazon. Этот алгоритм рассчитывает подобие предметов как косинус между векторами покупок в матрице пользователей
и предметов. Рассмотрим его работу на примере. Пусть U – клиенты; R – товары; Y – действия («Купил»/«Не купил»).
Таким образом, пользователь, находящийся на странице описания r1, получит r3 в качестве рекомендации; на странице r2 — r3 и на странице r3 — r1 (и затем r2). В данном алгоритме используется
один коэффициент на каждую пару предметов (косинус), на основании которого и создаются рекомендации. То есть для n предметов потребуется рассчитать и сохранить
Из-за простоты алгоритма вытекают его недостатки:
рекомендации тривиальны (предлагается всё наиболее популярное);
не учитываются интересы конкретного пользователя un;
не учитывается степень сходства ресурсов r и rn;
косинусов.
проблема «холодного старта»;
надо хранить попарные корреляции между объектами;
надо хранить всю матрицу F.
Фильтрация по схожести субъектов (user-based filtration) базируется на измерении подобия пользователей – анализируются отношения между пользователями, выясняется подобие их интересов. Где
сходство субъектов – это корреляция строк матрицы F.
Системы КФ, работающие по принципу схожести субъекта, обычно применяют двухступенчатую схему:
Находят тех, кто разделяет оценочные суждения активного (прогнозируемого) пользователя.
Используют оценки сходно мыслящих людей, найденных на первом шаге, для вычисления прогноза.
Данный метод позволяет избавится от тривиальных рекомендаций и учесть интересы конкретного
пользователя. Но опять же присутствуют следующие недостатки:
не учитывается степень сходства ресурсов r и rn;
проблема «холодного старта»;
надо хранить всю матрицу F;
нечего рекомендовать нетипичным или новым пользователям.
В конечном счете, модели, хранящие исходные данные (Memory-based) в силу простых методов легко
понять и легко реализовать в приложениях. Создано большое количество библиотек, реализующие описанные методы. Однако, есть несколько важных недостатков: не хватает теоретического обоснования,
так как придумано много способов оценить сходство, придумано много гибридных методов, но неясно,
как выбрать лучший; большим недостатком является необходимость хранения огромной матрицы F.
Перечисленных недостатков лишены неявные модели.
Другой класс методов КФ – латентные модели – в основывается на скрытом наблюдении обычного поведения пользователя (в противоположность искусственному, порождённому необходимостью оценивать).
В этих системах вы наблюдаете, как поступил данный пользователь, и как — другие (какую музыку они
слушали, какие композиции приобрели), и используете полученные данные, чтобы предсказать поведение пользователя в будущем, или предсказать, как пользователь желал бы поступить при наличии
определённой возможности. Эти предсказания должны быть отфильтрованы согласно логике бизнеса.
Например, бесполезно предлагать кому-либо купить музыкальный файл, который у него уже имеется.
Ключевыми особенностями латентных моделей является то, что они не хранят матрицу F всех сведений об объектах и субъектах, а хранят лишь профили клиентов. Для получения результатов проводится
оценивание профилей клиентов и объектов. При этом принимается, что сходство клиентов и объектов –
это сходство их профилей. По данным протокола транзакций D оцениваются векторы:
– профили субъектов;
– профили объектов.
Среди множества неявных моделей наиболее часто выделяют следующие:
Кластеризация;
Матричная факторизация: S = T, по, должны восстанавливаться;
Поиск ассоциативных правил.
Кластерный анализ — задача разбиения заданной выборки объектов (ситуаций) на непересекающиеся
подмножества, называемые кластерами, так, чтобы каждый кластер состоял из схожих объектов, а объекты разных кластеров существенно отличались. Методы кластеризации можно разделить на два типа:
Жесткая кластеризация, когда Мягкая кластеризация,
– степени принадлежности кластерам.
Для кластеризации в рамках латентных моделей прибегают к методу усреднения по блокам. Примером
может служить алгоритм BBAC (Bregman Block Average).
Метод поиска ассоциативных правил достаточно часто встречается в электронной торговле. В самом
общем виде смысл его заключается в генерации рекомендации по размещению товаров на страницах с
учетом того, какие товары покупают обычно за одну транзакцию. Одной из популярных реализаций метода является алгоритм Apriori.
Есть база данных покупок, состоящая из номера транзакции и списка купленных товаров. Необходимо определить наиболее часто встречающиеся наборы товаров.
Работа данного алгоритма состоит из нескольких этапов, каждый из этапов состоит из следующих
шагов:
формирование кандидатов;
подсчет кандидатов.
Формирование кандидатов (candidate generation) - этап, на котором алгоритм, сканируя базу данных, создает множество i-элементных кандидатов (i - номер этапа). На этом этапе поддержка кандидатов не рассчитывается.
Подсчет кандидатов (candidate counting) - этап, на котором вычисляется поддержка (количество
вхождений набора) каждого i-элементного кандидата. Здесь же осуществляется отсечение кандидатов,
поддержка которых меньше минимума, установленного пользователем (min_sup). Оставшиеся iэлементные наборы называем часто встречающимися.
На первом этапе происходит формирование одноэлементных кандидатов. Далее алгоритм подсчитывает
поддержку одноэлементных наборов. Наборы с уровнем поддержки меньше установленного min_sup , отсекаются.
Далее происходит формирование двухэлементных кандидатов, подсчет их поддержки и отсечение
наборов с уровнем поддержки, меньшим min_sup. Оставшиеся двухэлементные наборы товаров, считающиеся часто встречающимися двухэлементными наборами ab, ac, bd, принимают участие в дальнейшей работе алгоритма.
Если смотреть на работу алгоритма прямолинейно, на последнем этапе алгоритм формирует трехэлементные наборы товаров, подсчитывает их поддержку и отсекает наборы с уровнем поддержки, меньшим
min_sup. В результате один из наборов товаров может быть назван часто встречающимся.
Латентные модели, основанные на оценивании профилей субъектов и объектов, обладают рядом преимуществ. Производимые оценки сходства клиентов и объектов более адекватны. С профилями объектов
и субъектов можно делать многое, в том числе содержательно интерпретировать, частично оценивать
по априорным данным, обновлять динамически по мере поступления данных, сравнивать целиком или по фрагментам. Важным преимуществом является снятие проблемы «холодного старта» и резко сокращается объем хранимых данных.
